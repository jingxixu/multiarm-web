<!DOCTYPE HTML>
<html>
	<head>
		<title>Grasping in the Wild:Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations</title>
		<meta charset="utf-8" />
		 <meta name="viewport" content="width=1000">
		<link rel="stylesheet" href="assets/css/main.css" />
		 <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-89797207-1', 'auto');
          ga('send', 'pageview');
        </script>

        <meta property="og:url"           content="https://graspinwild.cs.columbia.edu/" />
	    <meta property="og:type"          content="website" />
	    <meta property="og:title"         content="Grasping in the Wild:Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations" />
	    <meta property="og:description"   content="Intelligent  manipulation  benefits  from  the  capacity  to flexibly  control  an  end-effector  with  high  degrees  of  freedom (DoF) and dynamically react to the environment. However,  due to the challenges of collecting effective training data and learning efficiently, most grasping algorithms today are limited to top-down movements and open-loop execution.  In this work, we propose a new low-cost hardware interface for collecting grasping demonstrations by people in diverse environments. Leveraging this data, we show that it is possible to train a robust end-to-end 6DoF closed-loop grasping model with reinforcement learning that transfers to real robots.  A key aspect of our grasping model is that it uses  “action-view”  based rendering to simulate future states with respect to different possible actions. By evaluating these states using a learned value function (Q-function), our method is able to better select corresponding actions that maximize total rewards (i.e., grasping success). Our final grasping system is able to achieve reliable 6DoF closed-loop grasping of novel objects across various scene configurations,  as well as dynamic scenes with moving objects." />
	    

	</head>
	<body id="top">


		<!-- Main -->
			<div id="main" style="padding-bottom:1em; padding-top: 5em; width: 60em; max-width: 70em; margin-left: auto; margin-right: auto;">
					<section id="four">

						<h1 style="text-align: center; margin-bottom: 0;"><font color="4e79a7">Grasping in the Wild:</font> </h1>
						<h2 style="text-align: center;">Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations</h2>

						<span class="image right" style="max-width: 40%; margin-top: 0.5em; margin-bottom: 0; border: 2px solid #415161;">
							<img src="images/teaser.jpg" alt="" />
						</span>

						<p> Intelligent  manipulation  benefits  from  the  capacity  to flexibly  control  an  end-effector  with  high  degrees  of  freedom (DoF) and dynamically react to the environment. However,  due to the challenges of collecting effective training data and learning efficiently, most grasping algorithms today are limited to top-down movements and open-loop execution.  In this work, we propose a new low-cost hardware interface for collecting grasping demonstrations by people in diverse environments. Leveraging this data, we show that it is possible to train a robust end-to-end 6DoF closed-loop grasping model with reinforcement learning that transfers to real robots.  A key aspect of our grasping model is that it uses  “action-view”  based rendering to simulate future states with respect to different possible actions. By evaluating these states using a learned value function (Q-function), our method is able to better select corresponding actions that maximize total rewards (i.e., grasping success). Our final grasping system is able to achieve reliable 6DoF closed-loop grasping of novel objects across various scene configurations,  as well as dynamic scenes with moving objects.
						</p>
						
						

						<!-- <hr/ style="margin-top: 1em">
						<h3>Highlights</h3>

						<section>
							<div class="box alt" style="margin-bottom: 0em;">

								<div class="row 50% uniform" style="width: 100%;">
									<div class="3u" style="margin-top: -5em; font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="https://ai.googleblog.com/2019/03/unifying-physics-and-deep-learning-with.html"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/logo-GoogleAI.png" alt="" style="height: 19em; width: auto;" /></span></a></div>
									<div class="3u" style="margin-left: 3em; margin-top: 1.6em; font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="https://www.nytimes.com/2019/03/26/technology/google-robotics-lab.html"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/logo-nyt.jpg" alt="" style="height: 6em; width: auto;" /></span></a></div>
									<div class="3u" style="margin-left: 6em; margin-top: 2.6em; font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/google-teaches-robot-to-toss-bananas-better-than-you-do"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/logo-ieeespectrum.png" alt="" style="height: 3em; width: auto;" /></span></a></div>
									
								</div>
							</div>
						</section> -->

						<hr style="margin-top: 0em;">
						<h3>Paper</h3>

						<!-- <hr/> -->
						<p style="margin-bottom: 1em;">Latest version: <a href="http://arxiv.org/abs/1912.04344">arXiv:1912.04344 [cs.CV]</a> or <a href="paper.pdf">here</a></p>

						<div class="12u$"><a href="https://arxiv.org/pdf/1912.04344.pdf"><span class="image fit" style="border: 1px solid; border-color: #888888;"><img src="images/paper-thumbnail.jpg" alt="" /></span></a></div>

						<p style="margin-bottom: 1em;">CAD Models for the 3D printed parts can be found: <a href="CAD_gripper.zip">here</a></p>

						<hr>
						<h3>Team</h3>

						<section>
							<div class="box alt" style="margin-bottom: 1em;">
								<div class="row 50% uniform" style="width: 90%;">
									<div class="2u" style="font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="http://vision.princeton.edu/people/shurans/"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/shuran-thumbnail.jpg" alt="" style="border-radius: 50%;" /></span>Shuran Song <sup>1,2</sup></a></div>

									<div class="2u" style="font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="http://andyzeng.github.io/"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/andy-thumbnail.jpg" alt="" style="border-radius: 50%;" /></span>Andy Zeng <sup>2</sup></a></div>
									
									<div class="2u" style="font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="http://johnnylee.net/"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/johnny-thumbnail.png" alt="" style="border-radius: 50%;" /></span>Johnny Lee <sup>2</sup></a></div>
									
									<div class="2u$" style="font-size: 0.7em; line-height: 1.5em; text-align: center;"><a href="https://www.cs.princeton.edu/~funk/"><span class="image fit" style="margin-bottom: 0.5em;"><img src="images/thomas-thumbnail.jpg" alt="" style="border-radius: 50%;" /></span>Thomas Funkhouser<sup>2</sup></a></div>
									
								</div>
							</div>
						</section>
						<sup>1</sup> Columbia University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup> Google
						<div class="row" style="margin-top: 1em">
							<div class="12u$ 12u$(xsmall)">
								<h3>Bibtex</h3>
								<pre><code>@article{song2020grasping,
title={Grasping in the Wild: Learning 6DoF Closed-Loop Grasping from Low-Cost Demonstrations},
author={ Song, Shuran and Zeng, Andy and Lee, Johnny and Funkhouser, Thomas},
journal={arXiv preprint arXiv:1912.04344},
year={2020} }
								</code>
							</pre>
							</div>
						</div>
						<hr/ style="margin-top: 1em">
						<!-- <div class="row">
							<div class="12u$ 12u$(xsmall)" style="text-align: center;">
		                    <video width="640"  playsinline="" muted="" autoplay="" loop="" >
		                        <source src="images/videos/data_video_combined2.mp4" type="video/mp4">
		                    </video>
	                		</div >
						</div> -->

						<div class="row">
							<div class="12u$ 12u$(xsmall)" style="text-align: center;">
								<h3>Technical Summary Video (with audio)</h3>
								<iframe id="match-video" width="640" height="360" style="margin-bottom: 2em; margin-left: auto; margin-right: auto; display:block;" src="https://www.youtube.com/embed/UPJjpIhXpZ8?rel=0" frameborder="0" allowfullscreen></iframe>
							</div>
						</div>

						<hr/ style="margin-top: 1em">
				        <h3>Acknowledgements</h3>
				        <p> We would like to thank Stefan Welker and Ivan Krasin for their help on designing the data collection device, Adrian Wong, Julian Salazar, and Sean Snyder for operational support,  Chad Richards for helpful feedback on writing, and Ryan Hickman for managerial support.  We are also grateful for financial support from Google and Amazon. </p>

						<hr/ style="margin-top: 1em">
				        <h3>Contact</h3>
				        <p>If you have any questions, please feel free to contact <a href="http://shurans.github.io/">Shuran Song</a></p>
						<hr/>
					</section>
			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="copyright">
						<li>Meet <a href="https://en.wikipedia.org/wiki/Danbo_(character)">Danbo</a> the cardboard robot.</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>
	</body>
</html>